# Applied-Machine-Learning-
Welcome to the "Applied Machine Learning" repository! This repository serves as a comprehensive resource for understanding and implementing various machine learning concepts in real-world scenarios.

## Notebooks Included:
Jupyter Notebooks are provided for each topic, containing detailed explanations, code implementations, and practical examples. These notebooks are designed to be beginner-friendly yet offer insights for advanced users.

### How to Use This Repository:
* Navigate through folders to find specific topics of interest. Each topic includes a dedicated notebook with step-by-step implementations and theoritical explaination.
* Clone or download the repository to your local machine and open the Jupyter Notebooks in your favorite environment. Follow along with the code and experiment with the provided examples.
* Feel free to contribute by adding your own implementations, enhancements, or additional topics. Your contributions can help create a valuable learning resource for the community.
### Getting Started:

* Clone the repository:

         git clone https://github.com/Syeda-Farhat/Applied-Machine-Learning-.git

  Start exploring the notebooks and enhance your machine learning skills!

* Your feedback is highly valuable. If you encounter any issues, have suggestions, or want to contribute, please open an issue or submit a pull request.
* The repository will be regularly updated with new notebooks covering additional applied machine learning topics. Stay tuned for more content!

# Topics 
* [Data Preprocessing and EDA using numeric Data](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Data_Preprocessing_and_EDA_using_numeric_Data.ipynb) :  [dataset](https://www.kaggle.com/code/weddou/uk-traffic-data-patterns-throught-space-time) .
* [Data Preprocessing and EDA using txt Data](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Data_Pre_processing_and_EDA_using_txt_data.ipynb) :  [dataset](https://www.kaggle.com/datasets/abhishek/spooky/data).

# Classification
* [Binary Classification](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/tree/main/Binary%20Classification)
  * [Logistic Regression](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Binary%20Classification/Logistic_Regression.ipynb)
  * [Support Vector Machines (SVM)](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Binary%20Classification/SVM.ipynb)
  * [Decision Trees](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Binary%20Classification/Decision_Trees_binary_classification.ipynb)
  * [Random Forest](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Binary%20Classification/Random_Forest_binary_classification.ipynb)
  * [Neural Networks](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/blob/main/Binary%20Classification/NN_binary_classification.ipynb)

* [Multi-Class Classification](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/tree/main/Multi-Class%20Classification)
  * Multinomial Logistic Regression
  * Support Vector Machines (SVM) with multi-class support
  * Decision Trees for multi-class problems
  * Random Forest for multi-class problems
  * Neural Networks for multi-class classification

* [Imbalanced Classification](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/tree/main/Imbalanced%20Classification)
  * Techniques for handling imbalanced datasets
  * Resampling methods (oversampling, undersampling)
  * Cost-sensitive learning
  * Ensemble methods for imbalanced data

* [Text Classification](https://github.com/Syeda-Farhat/Applied-Machine-Learning-/tree/main/Text%20Classification)
  * Natural Language Processing for text classification
  * Bag-of-Words and TF-IDF representations
  * Word embeddings (e.g., Word2Vec, GloVe)
  * Recurrent Neural Networks (RNN) for text classification
  * Transformer models (e.g., BERT) for text classification

* [Image Classification]
  * Convolutional Neural Networks (CNN)
  * Transfer Learning with pre-trained models (e.g., ResNet, VGG)
  * Data augmentation techniques for image data
  * Fine-tuning models for specific tasks

* [Ensemble Methods]
  * Bagging (e.g., Bootstrap Aggregating)
  * Boosting (e.g., AdaBoost, Gradient Boosting)
  * Stacking multiple models

# Regression

* [Linear Regression]
  * Simple Linear Regression
  * Multiple Linear Regression
  * Polynomial Regression

* [Regularization in Regression]
  * Ridge Regression
  * Lasso Regression
  * Elastic Net Regression

* [Decision Trees for Regression]
  * Regression Trees
  * Random Forest for regression
  * Gradient Boosted Trees for regression

* [Support Vector Machines (SVM) for Regression]
  * Support Vector Regression (SVR)
* [Ensemble Methods for Regression]
  * Bagging and boosting techniques for regression tasks
  * Stacking models for improved regression performance
